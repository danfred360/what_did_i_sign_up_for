import os
from langchain.document_loaders import AsyncHtmlLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_transformers import BeautifulSoupTransformer
from .provider import VectorDBProvider, RecordNotFound
from .llm import LLMProvider

class DocumentLoader():
    def __init__(self):
        self.vectordb = VectorDBProvider()
        self.llm = LLMProvider()
        self.file_path = os.environ.get('INPUT_FILES_DIRECTORY')
        if not os.path.exists(self.file_path):
            raise Exception(f'Input directory at {self.file_path} does not exist.')

    def load_document(self, file_path: str, file_id: int, name: str, description: str, url: str, generate_embeddings: bool = True):
        if not os.path.exists(file_path):
            raise Exception(f'File {file_path} not found')

        with open(file_path, 'r') as f:
            contents = f.read()

        try:
            self.vectordb.connect()
            document = self.vectordb.create_file_document(
                file_id, 
                name, 
                description, 
                contents, 
                url
            )
        except Exception as e:
            self.vectordb.disconnect()
            raise e
        self.vectordb.disconnect()

        try:
            self.llm.generate_segments_for_document(document['id'], generate_embeddings)
        except Exception as e:
            raise e
        return document
    
    def load_documents_from_input_files_dir(self, generate_embeddings=False):
        loaded_documents = []
        collection_directories = os.listdir(self.file_path)
        for collection_name in collection_directories:
            if collection_name == 'README.md':
                continue
            try:
                self.vectordb.connect()
                collection = self.vectordb.get_collection_by_name(collection_name)
            except RecordNotFound:
                try:
                    collection = self.vectordb.create_collection(
                        collection_name,
                        'Generated by file document loader',
                    )
                except Exception as e:
                    raise e
            except Exception as e:
                raise e
            finally:
                self.vectordb.disconnect()
            

            file_class_directories = os.listdir(os.path.join(self.file_path, collection_name))
            for file_class_name in file_class_directories:
                if file_class_name == 'terms_of_service':
                    file_class_id = 1
                elif file_class_name == 'privacy_policy':
                    file_class_id = 2
                else:
                    file_class_id = 3
                file_names = os.listdir(os.path.join(self.file_path, collection_name, file_class_name))
                for file_name in file_names:
                    try:
                        self.vectordb.connect()
                        file = self.vectordb.get_file_by_name(file_name)
                    except RecordNotFound:
                        try:
                            file = self.vectordb.create_file(
                                collection['id'],
                                file_class_id,
                                file_name,
                                'Generated by file document loader',
                                'foo.com'
                            )
                        except Exception as e:
                            raise e
                    except Exception as e:
                        raise e
                    finally:
                        self.vectordb.disconnect()
                    
                    document_names = os.listdir(os.path.join(self.file_path, collection_name, file_class_name, file_name))
                    for document_name in document_names:
                        document_path = os.path.join(self.file_path, collection_name, file_class_name, file_name, document_name)
                        try:
                            self.vectordb.connect()
                            self.vectordb.get_file_document_by_name(file['id'], document_name)
                        except RecordNotFound:
                            document = self.load_document(
                                document_path, 
                                file['id'], 
                                document_name,
                                'Generated by file document loader', 
                                'foo.com', 
                                generate_embeddings
                            )
                            loaded_documents.append({'id': document['id'], 'name': document['name']})
        return loaded_documents
        
    def load_file_from_url(self, url: str, collection_id: int = 1, file_class_id = 3, generate_embeddings: bool = False):
        loader = AsyncHtmlLoader(url)
        docs = loader.load()
        bs_transformer = BeautifulSoupTransformer()
        tags_to_extract = [
            "title",
            "p",
            "li",
            "div",
            "a",
            "span"
        ]
        docs_transformed = bs_transformer.transform_documents(docs, tags_to_extract=tags_to_extract)
        doc = docs_transformed[0]

        # running into rate limiting issues when extracting metadata

        # schema = {
        #     "properties": {
        #         "document_name": {"type": "string"},
        #         "document_summary": {"type": "string"}
        #     },
        #     "required": ["document_name", "document_summary"]
        # }

        # splitter = RecursiveCharacterTextSplitter()
        # splits = splitter.split_documents(docs_transformed)
        # extracted_content = self.llm.extract_document_metadata(
        #     schema=schema,
        #     contenst=splits[0].page_content
        # )

        try:
            title = url
            description = "Generated by url document loader"
            self.vectordb.connect()
            file = self.vectordb.create_file(
                collection_id,
                file_class_id,
                title or url,
                description,
                url
            )
            document = self.vectordb.create_file_document(
                file['id'], 
                title or url, 
                description, 
                doc.page_content, 
                url
            )
        except Exception as e:
            raise Exception(f'Failed to load file from url {url} with error: {e}')
        finally:
            self.vectordb.disconnect()
        try:
            self.llm.generate_segments_for_document(document['id'], generate_embeddings)
        except Exception as e:
            raise Exception(f'Failed to generate segments for document {document["id"]} with error: {e}')
        return file
    
    def process_file(self, file_id: int, generate_embeddings: bool = False):
        try:
            self.vectordb.connect()
            file = self.vectordb.get_file(file_id)
        except RecordNotFound:
            raise Exception(f'File with id {file_id} not found')
        finally:
            self.vectordb.disconnect()
        
        loader = AsyncHtmlLoader(file['url'])
        docs = loader.load()
        bs_transformer = BeautifulSoupTransformer()
        tags_to_extract = [
            "title",
            "p",
            "li",
            "div",
            "a",
            "span"
        ]
        docs_transformed = bs_transformer.transform_documents(docs, tags_to_extract=tags_to_extract)
        doc = docs_transformed[0]

        try:
            title = file['url']
            description = "Generated by url document loader"
            self.vectordb.connect()
            document = self.vectordb.create_file_document(
                file_id, 
                title,
                description, 
                doc.page_content, 
                file['url']
            )

            updated_file = self.vectordb.update_file(
                file_id
            )
        except Exception as e:
            raise Exception(f'Failed to process file with id {file_id} with error: {e}')
        finally:
            self.vectordb.disconnect()
        try:
            self.llm.generate_segments_for_document(document['id'], generate_embeddings)
        except Exception as e:
            raise Exception(f'Failed to generate segments for document {document["id"]} with error: {e}')
        return updated_file
